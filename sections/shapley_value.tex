\begin{frame}{Shapley Value - Intuition}
 Shapley value for a feature $j$: average change in prediction that a subset of features receives when the feature $j$ joins them.
\end{frame}
\begin{frame}{Shapley Value - Feature Contribution}
\begin{equation}
	\phi_j(val_{\bm{x}})=\sum_{S\subseteq\{1,\ldots,p\} \backslash \{j\}}\frac{|S|!\left(p-|S|-1\right)!}{p!}\left(val_{\bm{x}}\left(S\cup\{j\}\right)-val_{\bm{x}}(S)\right)
\end{equation}
\begin{itemize}
	\item Contribution of $j$-th feature value to the prediction (\emph{payout})
	\item Normalized: weighted and summed over all possible feature combinations
	\item $j$-th feature value
	\item $val_{\bm{x}}(S)$: value of players in $S$ %\red{to explain $\bm{x}$}
	\item $S$: a subset of features used in the model (\emph{coalition})
	\item $\bm{x}$: vector of feature values of an instance to be explained
	\item $p$: nr. features
\end{itemize}
\end{frame}

\begin{frame}{Shapley Value - The Value Function}
\begin{equation}
	val_{x}(S)=\int\hat{f}(x_{1},\ldots,x_{p})d\mathbb{P}_{x\notin{}S}-E_X(\hat{f}(X))
\end{equation}
\begin{itemize}
	\item Payout function for coalitions of players (feature values)
	\item Predicts feature values in $S$
	\item Marginalizes over features that are not in $S$
	\item Multiple integrations for each feature that is not in $S$
\end{itemize}
\end{frame}

\begin{frame}{Shapley Value - The Value Function - Example}
\begin{equation}
val_{x}(\{1,3\})=\int_{\mathbb{R}}\int_{\mathbb{R}}\hat{f}(x_{1},X_{2},x_{3},X_{4})d\mathbb{P}_{X_2X_4}-E_X(\hat{f}(X))
\end{equation}
\begin{itemize}
	\item $S = \{1,3\}$: features in coalition
	\item $p = 4$: tot. model features
\end{itemize}
\end{frame}

\input{sections/shapley_value_properties.tex}

\begin{frame}{Shapley Value - Exact Estimation}
	\begin{itemize}
		\item All possible subsets (coalitions) of feature values have to be evaluated with and without the $j$-th feature.
		\item The number of possible coalitions increases exponentially as the the number of features increases.
	\end{itemize}
\end{frame}
\begin{frame}{Shapley Value - Approximation\footnotemark}
\begin{equation}
	\hat{\phi}_{j}=\frac{1}{M}\sum_{m=1}^M\left(\hat{f}(\bm{x}^{m}_{+j})-\hat{f}(\bm{x}^{m}_{-j})\right)
\end{equation}
\begin{itemize}
	\item Monte-Carlo Sampling
	\item $\hat{f}(\bm{x}^{m}_{+j})$
	\begin{itemize}
		\item prediction for a data point $\bm{x}^m$
		\item random number of features replaced by feature values from a random data point $\bm{z}^m$.
		\item uses the feature value $x^m_j$
	\end{itemize}
	\item $\hat{f}(\bm{x}^{m}_{-j})$
	\begin{itemize}
		\item like $\hat{f}(\bm{x}^{m}_{+j})$
		\item uses the random feature value $z^m_j$
	\end{itemize}
\end{itemize}
\footnotetext[1]{\citeauthor{vstrumbelj2014explaining} (\citeyear{vstrumbelj2014explaining})}
\end{frame}